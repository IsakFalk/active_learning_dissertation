% I may change the way this is done in a future version, 
%  but given that some people needed it, if you need a different degree title 
%  (e.g. Master of Science, Master in Science, Master of Arts, etc)
%  uncomment the following 3 lines and set as appropriate (this *has* to be before \maketitle)
% \makeatletter
% \renewcommand {\@degree@string} {Master of Things}
% \makeatother

\title{Active Learning Regression by Mitigating Domain Drift}
\author{John Isak Texas Falk}
\department{Department of Computer Science}

\maketitle
\makedeclaration

\begin{abstract} % 300 word limit
  % Motivation / Purpose
  Active learning enables an algorithm to label a small proportion of a full
  dataset, where labels are unknown, in such a way that training on this smaller
  labelled subset will perform similar to as if the algorithm was trained on the
  full datasets with all labels known. When labelling data is costly but finding
  instances cheap, this can lead to massive cost reduction over supervised
  learning.

  % Problem
  Active learning can be considered for both classification and regression.
  While active learning for classification has been explored both theoretically
  and practically, there is much less work done on regression.

  % Method
  In this work we focus on noiseless regression where we devise an algorithm
  that chooses instances to label sequentially and train a Kernel Ridge Regression
  on this data. Central to this is the Frank Wolfe algorithm which greedily
  optimises the Maximum Mean Discrepancy between the full dataset and currently
  chosen instances. This leads to an algorithm that optimises an upper bound on
  the empirical risk of the estimator trained on the built train set. We try to
  control the true generalisation error but current results from convergence of
  Frank Wolfe means we cannot say whether or not this improves upon random
  sampling in theory.

  % Results
  We apply this algorithm to a wide range of datasets and compare it to leverage
  score sampling and random sampling. We show that the algorithm performs
  competitively compared to the other algorithms and illustrate the advantage of active
  learning in practice. We also show that it dominates the other methods in the
  agnostic setting of both regression and classification.

  % Conclusion
  This shows that using Frank Wolfe to mitigate domain drift is competitive and
  works well in practice, with learning curves that show better performance
  than random sampling on a wide range of datasets in both agnostic and
  realisable setting.
\end{abstract}

\begin{impactstatement}

% 	UCL theses now have to include an impact statement. \textit{(I think for REF reasons?)} The following text is the description from the guide linked from the formatting and submission website of what that involves. (Link to the guide: {\scriptsize \url{http://www.grad.ucl.ac.uk/essinfo/docs/Impact-Statement-Guidance-Notes-for-Research-Students-and-Supervisors.pdf}})

% \begin{quote}
% The statement should describe, in no more than 500 words, how the expertise, knowledge, analysis,
% discovery or insight presented in your thesis could be put to a beneficial use. Consider benefits both
% inside and outside academia and the ways in which these benefits could be brought about.

% The benefits inside academia could be to the discipline and future scholarship, research methods or
% methodology, the curriculum; they might be within your research area and potentially within other
% research areas.

% The benefits outside academia could occur to commercial activity, social enterprise, professional
% practice, clinical use, public health, public policy design, public service delivery, laws, public
% discourse, culture, the quality of the environment or quality of life.

% The impact could occur locally, regionally, nationally or internationally, to individuals, communities or
% organisations and could be immediate or occur incrementally, in the context of a broader field of
% research, over many years, decades or longer.

% Impact could be brought about through disseminating outputs (either in scholarly journals or
% elsewhere such as specialist or mainstream media), education, public engagement, translational
% research, commercial and social enterprise activity, engaging with public policy makers and public
% service delivery practitioners, influencing ministers, collaborating with academics and non-academics
% etc.

% Further information including a searchable list of hundreds of examples of UCL impact outside of
% academia please see \url{https://www.ucl.ac.uk/impact/}. For thousands more examples, please see
% \url{http://results.ref.ac.uk/Results/SelectUoa}.
% \end{quote}

The knowledge and algorithms in this dissertation have the potential for
industrial use in any setting where labelling is costly, or when there is a
fixed budget of how many instances it is possible to label. This is a setting
which occur in many different areas, to name a few, medical healthcare, process
engineering, natural language processing and data mining of documents. As
this contribution is derived from theoretical considerations, it can be used
both locally and internationally, by anyone anywhere.

From an academic point of view, the information and knowledge in this
dissertation will act as a springboard for future researchers and students, and
add to the existing pool of knowledge in the field of machine learning. The hope
is that this will foster further ideas on how to improve the field of active
learning for regression, building on results derived here and extending it to
more general and different settings.
\end{impactstatement}

\begin{acknowledgements}
  To my parents, thank you.
  \newline
  \newline
  To Carlo and Massi, Cheers!
\end{acknowledgements}

\setcounter{tocdepth}{2} 
% Setting this higher means you get contents entries for
%  more minor section headers.

\tableofcontents
\listoffigures
\listoftables

