\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{boyd04_convex}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Appendix}{51}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Proofs}{51}{section.6.1}\protected@file@percent }
\newlabel{sec:appendix-proofs}{{6.1}{51}{Proofs}{section.6.1}{}}
\newlabel{sec:appendix-proofs@cref}{{[section][1][6]6.1}{[1][51][]51}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Convex Analysis}{51}{section.6.2}\protected@file@percent }
\@writefile{loe}{\addvspace {10\p@ }}
\@writefile{loe}{\contentsline {definition}{\numberline {13}Definition}{51}{definition.13}\protected@file@percent }
\newlabel{def:conv-hull}{{13}{51}{}{definition.13}{}}
\newlabel{def:conv-hull@cref}{{[definition][13][]13}{[1][51][]51}}
\newlabel{eq:conv-hull}{{6.1}{51}{}{equation.6.2.1}{}}
\newlabel{eq:conv-hull@cref}{{[equation][1][6]6.1}{[1][51][]51}}
\@writefile{loe}{\contentsline {definition}{\numberline {14}Definition}{51}{definition.14}\protected@file@percent }
\newlabel{def:aff-hull}{{14}{51}{}{definition.14}{}}
\newlabel{def:aff-hull@cref}{{[definition][14][]14}{[1][51][]51}}
\newlabel{eq:aff-hull}{{6.2}{51}{}{equation.6.2.2}{}}
\newlabel{eq:aff-hull@cref}{{[equation][2][6]6.2}{[1][51][]51}}
\@writefile{loe}{\contentsline {definition}{\numberline {15}Definition}{51}{definition.15}\protected@file@percent }
\newlabel{def:relative-interior}{{15}{51}{}{definition.15}{}}
\newlabel{def:relative-interior@cref}{{[definition][15][]15}{[1][51][]51}}
\newlabel{eq:relative-interior}{{6.3}{51}{}{equation.6.2.3}{}}
\newlabel{eq:relative-interior@cref}{{[equation][3][6]6.3}{[1][51][]51}}
\@writefile{loe}{\contentsline {definition}{\numberline {16}Definition}{51}{definition.16}\protected@file@percent }
\newlabel{def:relative-boundary}{{16}{51}{}{definition.16}{}}
\newlabel{def:relative-boundary@cref}{{[definition][16][]16}{[1][51][]51}}
\newlabel{eq:relative-boundary}{{6.4}{51}{}{equation.6.2.4}{}}
\newlabel{eq:relative-boundary@cref}{{[equation][4][6]6.4}{[1][51][]51}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Experiments}{51}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Procedures}{51}{subsection.6.3.1}\protected@file@percent }
\newlabel{alg:experiment-agnostic}{{\caption@xref {alg:experiment-agnostic}{ on input line 55}}{52}{Procedures}{subsection.6.3.1}{}}
\newlabel{alg:experiment-agnostic@cref}{{[subsection][1][6,3]6.3.1}{[1][51][]52}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Experimental procedure (Agnostic)\relax }}{52}{algorithm.4}\protected@file@percent }
\newlabel{alg:experiment-realisable}{{\caption@xref {alg:experiment-realisable}{ on input line 94}}{53}{Procedures}{ALG@line.ALG@line.4.26}{}}
\newlabel{alg:experiment-realisable@cref}{{[subsection][1][6,3]6.3.1}{[1][51][]53}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Experimental procedure (Realisable)\relax }}{53}{algorithm.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Plots}{54}{subsection.6.3.2}\protected@file@percent }
\newlabel{figs:agnostic-regression-learning-curves}{{\caption@xref {figs:agnostic-regression-learning-curves}{ on input line 139}}{54}{Plots}{figure.caption.12}{}}
\newlabel{figs:agnostic-regression-learning-curves@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]54}}
\newlabel{fig:learning-curve-agnostic-bike-sharing}{{\caption@xref {fig:learning-curve-agnostic-bike-sharing}{ on input line 142}}{54}{Plots}{figure.caption.12}{}}
\newlabel{fig:learning-curve-agnostic-bike-sharing@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]54}}
\newlabel{sub@fig:learning-curve-agnostic-bike-sharing}{{}{54}{Plots}{figure.caption.12}{}}
\newlabel{sub@fig:learning-curve-agnostic-bike-sharing@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]54}}
\newlabel{fig:learning-curve-agnostic-boston}{{\caption@xref {fig:learning-curve-agnostic-boston}{ on input line 147}}{54}{Plots}{figure.caption.12}{}}
\newlabel{fig:learning-curve-agnostic-boston@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]54}}
\newlabel{sub@fig:learning-curve-agnostic-boston}{{a}{54}{Plots}{figure.caption.12}{}}
\newlabel{sub@fig:learning-curve-agnostic-boston@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]54}}
\newlabel{fig:learning-curve-agnostic-concrete}{{\caption@xref {fig:learning-curve-agnostic-concrete}{ on input line 153}}{54}{Plots}{figure.caption.12}{}}
\newlabel{fig:learning-curve-agnostic-concrete@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]54}}
\newlabel{sub@fig:learning-curve-agnostic-concrete}{{b}{54}{Plots}{figure.caption.12}{}}
\newlabel{sub@fig:learning-curve-agnostic-concrete@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]54}}
\newlabel{fig:learning-curve-agnostic-red_whine}{{\caption@xref {fig:learning-curve-agnostic-red_whine}{ on input line 158}}{54}{Plots}{figure.caption.12}{}}
\newlabel{fig:learning-curve-agnostic-red_whine@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]54}}
\newlabel{sub@fig:learning-curve-agnostic-red_whine}{{c}{54}{Plots}{figure.caption.12}{}}
\newlabel{sub@fig:learning-curve-agnostic-red_whine@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]54}}
\newlabel{fig:learning-curve-agnostic-white_wine}{{\caption@xref {fig:learning-curve-agnostic-white_wine}{ on input line 164}}{54}{Plots}{figure.caption.12}{}}
\newlabel{fig:learning-curve-agnostic-white_wine@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]54}}
\newlabel{sub@fig:learning-curve-agnostic-white_wine}{{d}{54}{Plots}{figure.caption.12}{}}
\newlabel{sub@fig:learning-curve-agnostic-white_wine@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]54}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Learning curves (bold line is mean with shaded region being \(\pm 1\) standard deviation over the 5 folds) for agnostic regression comparing FW (KH) with MC and Levscore. The \(y\)-axis is MSE (Mean Squared Error), \(x\)-axis is \(t\) (number of datapoints in current active learning train set). A good algorithm will have a trajectory that goes down quickly with \(t\). MC is baseline.\relax }}{54}{figure.caption.12}\protected@file@percent }
\newlabel{figs:realisable-regression-learning-curves}{{\caption@xref {figs:realisable-regression-learning-curves}{ on input line 175}}{55}{Plots}{figure.caption.13}{}}
\newlabel{figs:realisable-regression-learning-curves@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]55}}
\newlabel{fig:learning-curve-realisable-bike-sharing}{{\caption@xref {fig:learning-curve-realisable-bike-sharing}{ on input line 178}}{55}{Plots}{figure.caption.13}{}}
\newlabel{fig:learning-curve-realisable-bike-sharing@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]55}}
\newlabel{sub@fig:learning-curve-realisable-bike-sharing}{{}{55}{Plots}{figure.caption.13}{}}
\newlabel{sub@fig:learning-curve-realisable-bike-sharing@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]55}}
\newlabel{fig:learning-curve-realisable-boston}{{\caption@xref {fig:learning-curve-realisable-boston}{ on input line 183}}{55}{Plots}{figure.caption.13}{}}
\newlabel{fig:learning-curve-realisable-boston@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]55}}
\newlabel{sub@fig:learning-curve-realisable-boston}{{a}{55}{Plots}{figure.caption.13}{}}
\newlabel{sub@fig:learning-curve-realisable-boston@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]55}}
\newlabel{fig:learning-curve-realisable-concrete}{{\caption@xref {fig:learning-curve-realisable-concrete}{ on input line 189}}{55}{Plots}{figure.caption.13}{}}
\newlabel{fig:learning-curve-realisable-concrete@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]55}}
\newlabel{sub@fig:learning-curve-realisable-concrete}{{b}{55}{Plots}{figure.caption.13}{}}
\newlabel{sub@fig:learning-curve-realisable-concrete@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]55}}
\newlabel{fig:learning-curve-realisable-red_whine}{{\caption@xref {fig:learning-curve-realisable-red_whine}{ on input line 194}}{55}{Plots}{figure.caption.13}{}}
\newlabel{fig:learning-curve-realisable-red_whine@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]55}}
\newlabel{sub@fig:learning-curve-realisable-red_whine}{{c}{55}{Plots}{figure.caption.13}{}}
\newlabel{sub@fig:learning-curve-realisable-red_whine@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]55}}
\newlabel{fig:learning-curve-realisable-white_wine}{{\caption@xref {fig:learning-curve-realisable-white_wine}{ on input line 200}}{55}{Plots}{figure.caption.13}{}}
\newlabel{fig:learning-curve-realisable-white_wine@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]55}}
\newlabel{sub@fig:learning-curve-realisable-white_wine}{{d}{55}{Plots}{figure.caption.13}{}}
\newlabel{sub@fig:learning-curve-realisable-white_wine@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]55}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Learning curves (bold line is mean with shaded region being \(\pm 1\) standard deviation over the 5 folds) for regression comparing FW (KH) with MC and Levscore. The \(y\)-axis is MSE (Mean Squared Error), \(x\)-axis is \(t\) (number of datapoints in current active learning train set). A good algorithm will have a trajectory that goes down quickly with \(t\). MC is baseline.\relax }}{55}{figure.caption.13}\protected@file@percent }
\newlabel{figs:agnostic-classification-learning-curves}{{\caption@xref {figs:agnostic-classification-learning-curves}{ on input line 211}}{56}{Plots}{figure.caption.14}{}}
\newlabel{figs:agnostic-classification-learning-curves@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]56}}
\newlabel{fig:learning-curve-agnostic-mnist}{{\caption@xref {fig:learning-curve-agnostic-mnist}{ on input line 214}}{56}{Plots}{figure.caption.14}{}}
\newlabel{fig:learning-curve-agnostic-mnist@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]56}}
\newlabel{sub@fig:learning-curve-agnostic-mnist}{{}{56}{Plots}{figure.caption.14}{}}
\newlabel{sub@fig:learning-curve-agnostic-mnist@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]56}}
\newlabel{fig:learning-curve-agnostic-yeast}{{\caption@xref {fig:learning-curve-agnostic-yeast}{ on input line 219}}{56}{Plots}{figure.caption.14}{}}
\newlabel{fig:learning-curve-agnostic-yeast@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]56}}
\newlabel{sub@fig:learning-curve-agnostic-yeast}{{a}{56}{Plots}{figure.caption.14}{}}
\newlabel{sub@fig:learning-curve-agnostic-yeast@cref}{{[subsection][2][6,3]6.3.2}{[1][54][]56}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Learning curves (bold line is mean with shaded region being \(\pm 1\) standard deviation over the 5 folds) for agnostic classification comparing FW (KH) with MC and Levscore. The \(y\)-axis is Accuracy, \(x\)-axis is \(t\) (number of datapoints in current active learning train set). A good algorithm will have a trajectory that goes up quickly with \(t\). MC is baseline.\relax }}{56}{figure.caption.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Datasets and Hyperparameters}{57}{subsection.6.3.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Table for Agnostic Regression containing dataset information and hyperparameters. First column is the name of the dataset, \(n\) is the size, \(d\) the number of dimensions, \(\lambda _{opt}\) and \(\sigma _{opt}\) the hyperparameters chosen for KRR using kCV\relax }}{57}{table.caption.15}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces Table for Realisable Regression containing dataset information and hyperparameters. First column is the name of the dataset, \(n\) is the size, \(d\) the number of dimensions, \(\lambda _{opt}\) and \(\sigma _{opt}\) the hyperparameters chosen for KRR using kCV\relax }}{57}{table.caption.16}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces Table for Agnostic Classification containing dataset information and hyperparameters. First column is the name of the dataset, \(n\) is the size, \(d\) the number of dimensions, \(\lambda _{opt}\) and \(\sigma _{opt}\) the hyperparameters chosen for KRR using kCV\relax }}{57}{table.caption.17}\protected@file@percent }
\@setckpt{appendices}{
\setcounter{page}{58}
\setcounter{equation}{4}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{6}
\setcounter{section}{3}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{3}
\setcounter{table}{3}
\setcounter{float@type}{8}
\setcounter{algorithm}{5}
\setcounter{ALG@line}{28}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{caption@flags}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{4}
\setcounter{bookmark@seq@number}{0}
\setcounter{parentequation}{0}
\setcounter{thmt@dummyctr}{50}
\setcounter{theorem}{26}
\setcounter{remark}{0}
\setcounter{definition}{16}
\setcounter{axiom}{0}
\setcounter{assumption}{6}
\setcounter{example}{2}
\setcounter{csvinputline}{4}
\setcounter{csvrow}{2}
\setcounter{csvcol}{5}
\setcounter{subfigure}{2}
\setcounter{subtable}{0}
\setcounter{NAT@ctr}{61}
\setcounter{algorithmicH}{5}
\setcounter{section@level}{2}
}
