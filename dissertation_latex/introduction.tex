\chapter{Introduction}
\label{ch:introduction}

\section{Background}
\label{sec:background}
A cornerstone of machine learning is the paradigm of supervised learning. In
supervised learning the goal is to learn an input-output (where the output is
also sometimes called a label) relationship from a finite sample of input and
output datapoints from the phenomenon of interest. The goal is to be able to
learn an approximately correct relationship from a finite number of datapoints
that generalises to a new set of datapoints from the same phenomenon, which we
represent as a joint distribution over the input domain and output co-domain.
However, in supervised learning the algorithm does not have any way of choosing
how this dataset is created as it is sampled from the joint distribution. This
puts some restrictions on its use in practice as certain algorithms are too
computationally expensive to train on full datasets or the case when instances
are cheap to collect, but expensive to label.

The second setting occurs frequently in practice. Today data is being created in
abundance due to human use of social media, email and devices
\cite{desjardins19_how}, and due to data being collected from industrial processes
\cite{qin14_proces_data_analy_era_big_data}. Much of this data is unstructured and
in most cases the output we want to predict is not available directly. An
example of this is the text data being generated by the web; platforms such as
Twitter produces massive amounts of free text which is not labeled at all. For
example, when trying to do sentiment analysis on sentences from Twitter, it is
necessary to heuristically assign a label to an instance or send it to an expert
for labeling \cite{pak10_twitt}. This begs the question if we can design
strategies for what instances we should label first in order to learn patterns
faster, in comparison to labeling instances at random.

Active learning \cite{cohn94_improv_gener_with_activ_learn} is a machine learning
paradigm which generalises supervised learning by allowing the algorithm in some
sense to decide what instances to query for the corresponding output. The hope
is that this will lead to close-to-optimal performance in much fewer labels
compared to a supervised learning algorithm trained on a dataset of the same
size. In this way, it is a question of the information content of the dataset.
By choosing instances carefully we may create a dataset that is richer in
information with respect to the pattern we want to learn than a dataset of same
size, given to us from nature.

As such, active learning is similar to semi-supervised learning
\cite{chapelle09_semi_super_learn_o} in that it tries to make efficient use of all
available data. However, where semi-supervised learning uses the unlabeled data
to improve performance by inferring aspects of the marginal distribution, active
learning builds a dataset by querying the unlabeled data and getting the
corresponding output. It is possible to combine the two \cite{zhu03_combin}.

As a concrete example, imagine the following problem: We are on \([0,
1] \subseteq \R\) and we know that there exists some true relationship
\(f(x) = \indic{w^{\ast} \leq x}\) where \(w^{\ast} \in (0, 1)\),
but we do not observe the output directly but have to ask for it, an operation we
call \emph{querying} an instance. 

Nature draws instances \(x \sim \rho_{\X}\) where \(\rho_{\X}\) is some
distribution over the domain \(\X = [0, 1]\). Our goal is to find a good guess
\(h_{w}(x) = \indic{w \leq x}\) so that we incur a small loss,
\(\Pr_{\rho_{\X}}(h_{w}(x) \neq f(x))\), in as few queries of labels as
possible. Since we know the form of the relationship, we also know that if we
have queried an instance \(x_{1}\) which leads to the pair \((x_{1}, f(x_{1}))\)
where \(f(x_{1}) = 0\) (which means that \(x_{1} \leq w^{\ast}\)) then we also
know that for any other \(x_{2} \leq x_{1} \leq w^{\ast}\), \(f(x_{2}) = 0\).
This means that \textbf{querying any instance smaller than} \(x_{1}\) \textbf{is unnecessary}.

It can be shown that for a set of \(O(\frac{1}{\epsilon})\) unlabeled
instances, an active learning algorithm have to query only \(O(\log
\frac{1}{\epsilon})\) instances in order to find a \(h_{w}\) such that \(\Pr_{\rho_{\X}}(h_{w}(x)
\neq f(x)) < \epsilon\) with high probability. Compared to supervised
learning which requires \(O(\frac{1}{\epsilon})\) this is an exponential
speedup \cite{dasgupta06_coars,dasgupta05_analy}!

In practice, it is often not so simple. Active learning has been shown to not
yield better performance than supervised learning when considering worst case
scenarios\footnote{Which is done in statistical learning theory.} which hints
that only when we can identify and exploit structure of the problem, such as the
knowledge of the threshold function in the example above, can we hope to improve
over normal supervised learning. In the end this has come down to identifying
conditions on the data-generating distribution and the target class which
enables active learning to improve over supervised learning
\cite{balkan15_activ_learn_moder_learn_theor}.

\section{Research Focus}
The theoretical foundations of active learning for binary classification is
fairly well-understood, with results which are essentially always at least as
good as supervised learning \cite{balcan10_true_sampl_compl_activ_learn}. However,
results for regression is more sparse and less well-developed. For regression,
the assumption is often that the bias term of the error decomposition is
negligible, see for example \cite{cohn96_activ_learn_with_statis_model}. There has
been attempts to control for this directly, but relies on assumptions that
basically reduces regression to classification
\cite{willett06_faster_rates_regres_activ_learn}. Thus a natural direction is to
consider active learning for regression based on statistical learning theory and
investigate how the bias term can be understood and controlled.

In general, statistical learning theory considers how to minimise the risk,
which is a much harder problem than minimising the empirical risk. This stems
from the problem of generalisation and the fact that good performance on the
train set does not necessarily imply good performance on the test set. However,
given that we know the data-generating distribution, active learning can be
shown to be closely related to quadrature \cite{briol15_frank_wolfe_bayes} and
optimal experimental design \cite{fedorov10_optim_exper_desig}. The main
difference is the setting and assumptions, for quadrature the distribution is in
general known and optimal experimental design assumes very
stringent conditions on the problem at hand.

In this sense we are interested in active learning procedures that are motivated
by statistical learning theory and grounded on error bounds through the use of
controlling the sampling and approximation error. Ideally we would like to find
necessary assumptions for active learning to yield performance improvements over
supervised learning, that is, an active learning algorithm with statistical
guarantees that performs better than supervised learning in probability.
Specifically, in this dissertation we aim to do the following 

\begin{itemize}
\item Review the literature on active learning for regression in a theoretical
  setting including necessary results from Reproducing Kernel Hilbert Space
  (hereafter \emph{RKHS}) theory and optimisation
\item Specify and find necessary conditions for enabling error bounds of the risk,
  which we term the objective
\item Derive an active learning algorithm for regression based on optimising this objective
\item Empirically evaluate and compare this algorithm to other active learning
  algorithms for regression
\end{itemize}

\section{Research Aims and Individual Research Objectives}
The aim of this dissertation is to critically analyse and summarise the
literature on active learning in the setting of regression and provide
conditions and assumption necessary for a theoretically grounded active learning
algorithm with guarantees to be possible. We do this by leaning on the
well-developed field of RKHS theory, which in some sense is an ideal setting for
statistical learning due to various theoretical properties such as the
reproducing property and the representer theorem.

We further aim to derive bounds on the quantity of interest, a modified excess
risk for active learning, and provide a framework for comparing active learning
algorithms to supervised learning algorithms by framing active learning as a
generalisation of supervised learning. In addition to this, we will make
connections with other fields and use recent advances in machine learning, based
on the Frank Wolfe algorithm applied to RKHS's.

Finally we aim to produce an algorithm which satisfy theoretical guarantees
which is shown to be empirically competitive with other similar algorithms. This
will be done through a rigorous investigation of how the algorithm perform in
practice by evaluating the algorithm on regression and finally classification
tasks, displaying the theoretical performance in practice and show that when
applied to settings where the theoretical assumptions do not hold, it's still
competitive.

\section{Value of this Research}
The contribution of this research will be the following:
\begin{itemize}
\item A review of the existing methods and approaches to active learning for
  regression with a focus on theory
\item An investigation and subsequent identification of an active learning
  regression area that is amenable to analysis and to advances of recent machine
  learning algorithms in order to improve upon current methods of active learning
  regression algorithms
\item A competitive active learning regression algorithm which synthesise methods from
  statistical learning theory, kernel theory and optimisation together with an
  analysis of its empirical performance compared to other benchmark algorithms
\end{itemize}